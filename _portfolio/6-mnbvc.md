---
title: "MNBVC超大规模中文语料集"
excerpt: "<img src='https://img.shields.io/github/stars/esbatmop/MNBVC?style=social' alt='GitHub stars'> MNBVC数据集包括新闻、作文、小说、书籍、杂志、论文、台词、帖子、wiki、古诗、歌词、商品介绍、笑话、糗事、聊天记录等一切形式的纯文本中文数据。数据均来源于互联网收集。<br/><img src='/images/projects/mnbvc/1.png' width='60%'>"
collection: portfolio
---

<img src='https://img.shields.io/github/stars/esbatmop/MNBVC?style=social' alt='GitHub stars'> 项目地址：[https://github.com/esbatmop/MNBVC](https://github.com/esbatmop/MNBVC)

## 项目概述

<p align=center>
	<img src="/images/projects/mnbvc/1.png" width="80%">
</p>

MNBVC项目是一个雄心勃勃的计划，旨在创建一个超大规模的中文语料库，名为“Massive Never-ending BT Vast Chinese corpus”。该项目于2023年1月1日由MOP里屋社区发起，致力于收集和整理海量的中文文本数据。

* **数据规模宏大:** MNBVC的目标是收集高达253T的数据，远超当前许多主流语料库的规模。目前项目已经完成了23.5%，数据量达到了59685GB。
* **内容包罗万象:** 该语料库不仅收录了新闻、小说、论文等常见文本，还涵盖了帖子、聊天记录、歌词、商品介绍等各种形式的中文数据，甚至包括了小众文化和网络用语。
* **数据来源广泛:** 所有数据均来自互联网，并通过脱敏处理，确保了数据的安全性和隐私性。

<p align=center>
	<img src="/images/projects/mnbvc/2.png" width="80%">
</p>

其中，我曾经负责多模态语料的收集。

<p align=center>
	<img src="/images/projects/mnbvc/3.png" width="80%">
</p>