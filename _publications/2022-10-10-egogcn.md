---
title: "[ACM 2022] Breaking Isolation: Multimodal Graph Fusion for Multimedia Recommendation by Edge-wise Modulation"
collection: publications
category: conferences
permalink: /publication/2022-10-10-egogcn
excerpt: 'Multimedia Recommendation, Graph Fusion, Edge-wise Modulation, Graph Convolutional Network (GCN)'
date: 2022-10-10
venue: 'ACM MM'
paperurl: 'https://dl.acm.org/doi/abs/10.1145/3503161.3548399'
bibtexurl: # empty
citation: # empyty
slidesurl: # empyty
---

**关键词**

- 多媒体推荐 / Multimedia Recommendation
- 图融合 / Graph Fusion
- 多模态动态 / Multimodal Dynamics
- 边调制 / Edge-wise Modulation
- 图卷积网络 / Graph Convolutional Network (GCN)
- 协同过滤 / Collaborative Filtering

ACM MM 2022: [https://dl.acm.org/doi/abs/10.1145/3503161.3548399](https://dl.acm.org/doi/abs/10.1145/3503161.3548399)

## 背景

随着多媒体内容在推荐系统中的广泛应用，用户与项目（内容）之间的交互日益呈现多模态特性，如视频、文本、音频等多种数据形式。传统推荐系统往往忽略了不同模态之间复杂且隐含的动态关系（multimodal dynamics），难以全面捕捉用户的真实偏好。以往基于GCN（图卷积网络）的多模态推荐方法主要有两类：
1. **图合并融合（Graph Mergence Fusion）**：将不同模态的子图简单拼接或合并，导致各模态之间信息交流不充分，无法捕捉深层次的模态关联。
2. **节点对齐融合（Node Alignment Fusion）**：构建大型异构图，使信息能够在模态间流动，但会引入大量噪音，难以扩展到大规模数据。

针对上述方法的不足，本文提出了一种新的图融合方法，旨在更有效地捕捉多模态间的变化和关联，提升多媒体推荐系统的性能。

<p align=center>
	<img src="/images/papers/2022-egogcn/egogcn-1.png" width="80%">
</p>

## 方法

论文提出了一种新型结构 **EgoGCN**，其核心创新在于 **EdGe-wise mOdulation (EGO) Fusion**，包括以下三大模块：

1. **多模态传播模块**  
   - 保持各模态的用户-项目子图，能够分别建模不同模态的用户偏好（variation）。
   - 在图传播的初始阶段，通过 EGO 融合机制实现信息在模态间的高效流动和互补。
   - EGO 融合分为两种调制方式：
     - **硬调制（Hard Modulation, EgoGCN-hard）**：基于用户-项目的相关性（affinity）进行邻居节点的“融合或保留”操作，只选取最重要的邻居节点信息进行多模态融合。
     - **软调制（Soft Modulation, EgoGCN-soft）**：为所有邻居节点学习影响力门控，根据不同模态间的影响强度自适应地控制信息流动，实现更细粒度的信息调节。

2. **ID 嵌入传播模块**  
   - 采用简化的图卷积操作对用户和项目的ID嵌入进行协同信号的传播，进一步精炼用户-项目的协同关系。
   - 该模块与多模态传播模块解耦，提高模型的简洁性与泛化能力。

3. **预测层**  
   - 将多模态特征与ID嵌入拼接，利用内积方式计算用户与项目的最终亲和度分数。

<p align=center>
	<img src="/images/papers/2022-egogcn/egogcn-2.png" width="100%">
</p>

## 实验

### 数据集
- **Movielens**：包含电影描述（文本）、预告片（视觉）、音轨（音频）三种模态信息。
- **Tiktok**：来自短视频平台，包含用户与短视频的互动行为及多模态特征。
- 两个数据集都极度稀疏（稀疏度 >99.6%），分别对每个用户的历史交互以8:1:1比例划分为训练、验证和测试集。

### 实验设置
- 与多种经典GCN模型及多模态融合方法进行对比，包括 GraphSAGE, NGCF, DisenGCN, GAT, MMGCN, HUIGN, LightGCN, GRCN 等。
- 主要评价指标：Precision@10, Recall@10, NDCG@10。
- 采用负采样与早停机制，使用 PyTorch 和 torch-geometric 实现。

### 消融实验
- 分析了EgoGCN中各模块和不同融合策略（如仅用ID嵌入、替换为传统图合并/节点对齐）的效果，验证了EGO融合的有效性。

## 结果

- EgoGCN-hard 和 EgoGCN-soft 在两个数据集上的所有指标均显著优于现有最佳方法（如GRCN）。
- 在Movielens数据集上，EgoGCN-hard 在Precision、Recall、NDCG上分别提升了6.26%、6.85%、6.94%。
- 在Tiktok数据集上，EgoGCN-soft 在Precision、Recall、NDCG上分别提升了12.31%、14.41%、10.33%。
- 消融实验表明：多模态传播、EGO融合机制和ID嵌入解耦均对提升性能有重要贡献。
- 进一步分析了EGO融合的超参数（如调制门控阈值𝜖）与层数（K, L）对性能的影响，发现EGO融合可有效平衡信息融合和噪音控制。

<p align=center>
	<img src="/images/papers/2022-egogcn/egogcn-3.png" width="100%">
</p>

<p align=center>
	<img src="/images/papers/2022-egogcn/egogcn-4.png" width="80%">
</p>

## 总结

本文提出了基于边调制的多模态图融合方法 EgoGCN，用于提升多媒体推荐系统的效果。通过引入EGO融合机制，实现了多模态间信息的高效、灵活流动，兼顾了模态间的变化与关联，有效缓解了噪音干扰。大量实验结果表明，EgoGCN在多媒体推荐任务上取得了当前最佳表现。未来工作将探索针对缺失模态情境下的更高级融合机制。
